{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "source": [
    "<div><img style=\"float: left; padding-right: 3em;\" src=\"https://avatars.githubusercontent.com/u/19476722\" width=\"150\" /><div/>\n",
    "\n",
    "# Earth Data Science Coding Challenge!\n",
    "Before we get started, make sure to read or review the guidelines below. These will help make sure that your code is **readable** and **reproducible**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "source": [
    "## Don't get **caught** by these Jupyter notebook gotchas\n",
    "\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:4800/format:webp/1*o0HleR7BSe8W-pTnmucqHA.jpeg\" width=300 style=\"padding: 1em; border-style: solid; border-color: grey;\" />\n",
    "\n",
    "  > *Image source: https://alaskausfws.medium.com/whats-big-and-brown-and-loves-salmon-e1803579ee36*\n",
    "\n",
    "These are the most common issues that will keep you from getting started and delay your code review:\n",
    "\n",
    "1. When you try to run some code on GitHub Codespaces, you may be prompted to select a **kernel**.\n",
    "   * The **kernel** refers to the version of Python you are using\n",
    "   * You should use the **base** kernel, which should be the default option. \n",
    "   * You can also use the `Select Kernel` menu in the upper right to select the **base** kernel\n",
    "2. Before you commit your work, make sure it runs **reproducibly** by clicking:\n",
    "   1. `Restart` (this button won't appear until you've run some code), then\n",
    "   2. `Run All`\n",
    "\n",
    "## Check your code to make sure it's clean and easy to read\n",
    "\n",
    "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSO1w9WrbwbuMLN14IezH-iq2HEGwO3JDvmo5Y_hQIy7k-Xo2gZH-mP2GUIG6RFWL04X1k&usqp=CAU\" height=200 />\n",
    "\n",
    "* Format all cells prior to submitting (right click on your code).\n",
    "* Use expressive names for variables so you or the reader knows what they are. \n",
    "* Use comments to explain your code -- e.g. \n",
    "  ```python\n",
    "  # This is a comment, it starts with a hash sign\n",
    "  ```\n",
    "\n",
    "## Label and describe your plots\n",
    "\n",
    "![Source: https://xkcd.com/833](https://imgs.xkcd.com/comics/convincing.png)\n",
    "\n",
    "Make sure each plot has:\n",
    "  * A title that explains where and when the data are from\n",
    "  * x- and y- axis labels with **units** where appropriate\n",
    "  * A legend where appropriate\n",
    "\n",
    "\n",
    "## Icons: how to use this notebook\n",
    "We use the following icons to let you know when you need to change something to complete the challenge:\n",
    "  * &#128187; means you need to write or edit some code.\n",
    "  \n",
    "  * &#128214;  indicates recommended reading\n",
    "  \n",
    "  * &#9998; marks written responses to questions\n",
    "  \n",
    "  * &#127798; is an optional extra challenge\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "55dccf8d4c03bba0b23eb02f560c8f38",
     "grade": false,
     "grade_id": "overview",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# The Camp Fire was the deadliest and costliest natural disaster of 2018\n",
    "\n",
    "\n",
    "![The Camp fire - a firefighter assessing burning building in Paradise, CA](https://static01.nyt.com/newsgraphics/2018/11/14/camp-fire-progression/assets/images/9971492an-2000_x2.jpg)\n",
    "> Image source: \n",
    "\n",
    "You can get started learning about the fire from the following sources:\n",
    "  * [Fire in Paradise](https://www.pbs.org/wgbh/frontline/documentary/fire-in-paradise/), a documentary from PBS\n",
    "  * [\"Hell on Earth\"](https://www.nytimes.com/interactive/2018/11/18/us/california-camp-fire-paradise.html) and [What's next after the Camp fire destroyed Paradise](https://www.nytimes.com/interactive/2018/12/26/us/paradise-california-camp-fire.html), interactive reporting from the New York Times\n",
    "  * [Incident report](https://www.fire.ca.gov/incidents/2018/11/8/camp-fire) from CalFire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aa89f8dcb8bff3cbe8ad459ace447127",
     "grade": false,
     "grade_id": "step-1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## STEP 1: SET UP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7853d8cb7416a8fc4548185fb02d87b2",
     "grade": false,
     "grade_id": "instr-import",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### YOUR TASK: Import necessary libraries\n",
    "1. In the cell below, making sure to keep the packages in order, add packages for:\n",
    "  * Generating interactive maps\n",
    "  * Work with DataFrames in Python (we will be using this package for its date utilities)\n",
    "  * Using hvplot to plot DataFrames AND xarray Datasets\n",
    "  \n",
    "2. In addition, add the following libraries:\n",
    "\n",
    "```python\n",
    "import pathlib\n",
    "import os\n",
    "from glob import glob\n",
    "import geopandas as gpd\n",
    "import subprocess\n",
    "import earthpy.appeears as etapp\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "import logging\n",
    "import warnings\n",
    "```\n",
    "\n",
    "3. Format your imports to comply with the PEP-8 standard\n",
    "\n",
    "&#127798; What are we using the rest of these packages for? See if you can figure it out as you complete the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "84870cded201b012b2c95438eafb3392",
     "grade": false,
     "grade_id": "ans-import",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Set up logging so AppeearsDownloader will log in notebook\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Ignore FutureWarning coming from hvplot\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5af32a56b586577bc0d07d572da1bfce",
     "grade": true,
     "grade_id": "tests-import",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# RUN THIS CELL TO TEST YOUR CODE - DO NOT MODIFY!\n",
    "import_pts = 0\n",
    "\n",
    "# Check that folium has been imported\n",
    "try:\n",
    "    folium.Map()\n",
    "    import_pts += 1\n",
    "    print('\\u2705 Great work! '\n",
    "          'You correctly imported the folium library.')\n",
    "except:\n",
    "    print('\\u274C Oops - folium was not imported.')\n",
    "    \n",
    "# Check that pandas has been imported properly\n",
    "try:\n",
    "    pd.DataFrame()\n",
    "    import_pts += 1\n",
    "    print('\\u2705 Great work! '\n",
    "          'You correctly imported the pandas library.')\n",
    "except:\n",
    "    print('\\u274C Oops - pandas was not imported correctly.')\n",
    "    \n",
    "# Check that hvplot has been imported\n",
    "try:\n",
    "    pd.DataFrame().hvplot\n",
    "    xr.Dataset().hvplot\n",
    "    import_pts += 2\n",
    "    print('\\u2705 Great work! '\n",
    "          'You correctly imported hvplot extensions')\n",
    "except:\n",
    "    print('\\u274C Oops - hvplot was not imported correctly.')\n",
    "\n",
    "# Subtract one point for any PEP-8 errors\n",
    "tmp_path = \"tmp.py\"\n",
    "with open(tmp_path, \"w\") as tmp_file:\n",
    "    tmp_file.write(In[-2])\n",
    "ignore_flake8 = 'W292,F401,E302'\n",
    "flake8_out = subprocess.run(\n",
    "    ['flake8', \n",
    "     '--ignore', ignore_flake8, \n",
    "     '--import-order-style', 'edited',\n",
    "     '--count', \n",
    "     tmp_path],\n",
    "    stdout=subprocess.PIPE,\n",
    ").stdout.decode(\"ascii\")\n",
    "print(flake8_out)\n",
    "import_pts -= int(flake8_out.splitlines()[-1])\n",
    "\n",
    "print(\n",
    "    \"\\n \\u27A1 You received {} out of 4 points.\".format(import_pts)\n",
    ")\n",
    "\n",
    "import_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c3f781ddbfa7b46e77201eb2a52ea0be",
     "grade": false,
     "grade_id": "instr-datadir",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We have one more setup task. We're not going to be able to load all our data directly from the web to Python this time. That means we need to set up a place for it on your computer (or in your Codespace).\n",
    "\n",
    "> **GOTCHA ALERT**: A lot of times in Python we say \"directory\" to mean a \"folder\" on your computer. The two words mean more or less the same thing.\n",
    "\n",
    "&#128187; YOUR TASK: In the cell below:\n",
    "  1. Copy the following code into the cell:\n",
    "        ```python\n",
    "        my_path = os.path.join(\n",
    "             pathlib.Path.home(), 'earth-analytics', 'data', 'camp-fire')\n",
    "        os.makedirs(my_path, exist_ok=True)\n",
    "        my_path\n",
    "        ```\n",
    "  2. Replace `my_path` with a descriptive variable name of your choice.\n",
    "     > **PLEASE!** For ease of grading, do not change anything about the **content** stored as `my_path`. If you do, I will not be able to run your code without individually downloading for each of you, which could take a lot of time.\n",
    "  4. Add descriptive comments about what this code is doing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8458730c591ff7b8e14b8dbe30f7cdf",
     "grade": false,
     "grade_id": "ans-datadir",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "43df7aec24ea0cfa9bbb693f7da4b34b",
     "grade": true,
     "grade_id": "tests-datadir",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# RUN THIS CELL TO TEST YOUR WORK - DO NOT MODIFY\n",
    "ans_dir = _\n",
    "print(ans_dir)\n",
    "dir_pts = 0\n",
    "\n",
    "if os.path.exists(ans_dir):\n",
    "    print('\\u2705 Great work! You created a project directory.')\n",
    "    dir_pts += 5\n",
    "else:\n",
    "    print(\"\\u274C Hmm, looks like you didn't create your project directory\")\n",
    "\n",
    "# Subtract one point for any PEP-8 errors\n",
    "tmp_path = \"tmp.py\"\n",
    "with open(tmp_path, \"w\") as tmp_file:\n",
    "    tmp_file.write(In[-2])\n",
    "ignore_flake8 = 'W292,F401,E302,F821'\n",
    "flake8_out = subprocess.run(\n",
    "    ['flake8',\n",
    "     '--ignore', ignore_flake8,\n",
    "     '--import-order-style', 'edited',\n",
    "     '--count',\n",
    "     tmp_path],\n",
    "    stdout=subprocess.PIPE,\n",
    ").stdout.decode(\"ascii\")\n",
    "print(flake8_out)\n",
    "dir_pts -= int(flake8_out.splitlines()[-1])\n",
    "\n",
    "print('\\u27A1 You earned {} of 5 points for creating a data directory'\n",
    "      .format(dir_pts))\n",
    "\n",
    "dir_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f2409180ae31499936c30c0d55bdeb3d",
     "grade": false,
     "grade_id": "step-2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## STEP 2: SITE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0db9bf346b04a3bb0510c10baabb34f1",
     "grade": false,
     "grade_id": "task-data-formats",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Earth Data Science data formats\n",
    "\n",
    "In Earth Data Science, we get data in three main formats:\n",
    "\n",
    "|  Data type  |  Descriptions | Common file formats | Python type |\n",
    "|-------------|---------------|---------------------|-------------|\n",
    "| Time Series | The same data points (e.g. streamflow) collected multiple times over time | Tabular formats (e.g. .csv, or .xlsx) | pandas DataFrame |\n",
    "| Vector | Points, lines, and areas (with coordinates) | Shapefile (often an archive like a `.zip` file because a Shapefile is actually a collection of at least 3 files) | geopandas GeoDataFrame |\n",
    "| Raster | Evenly spaced spatial grid (with coordinates) | GeoTIFF (`.tif`), NetCDF (`.nc`), HDF (`.hdf`)| rioxarray DataArray |\n",
    "\n",
    "&#128214; Read more about [vector data](https://www.earthdatascience.org/courses/use-data-open-source-python/intro-vector-data-python/spatial-data-vector-shapefiles/) and [raster data](https://www.earthdatascience.org/courses/intro-to-earth-data-science/file-formats/use-spatial-data/use-raster-data/) in the textbook.\n",
    "\n",
    "&#9998; For this coding challenge, we are interested the Camp Fire boundary as the study boundary. In the cell below, answer the following question: **What data type do you think the fire boundary will be?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WRITE YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5f99f94324bc912c97d666491126d70e",
     "grade": false,
     "grade_id": "instr-boundary",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "&#128187; YOUR TASK:\n",
    "  * Head to the [Wildland Fire Interagency Geospatial Services (WFIGS) Historic Perimeters 2018 API explorer site](https://data-nifc.opendata.arcgis.com/datasets/nifc::historic-perimeters-2018/api) from the National Interagency Fire Center.\n",
    "  * Add filters until you get the single, final, perimeter. You may wish to try requesting the results in Python rather than on the API site since it will be easier to see how many records you get. One example that works:\n",
    "    * incidentname like 'CAMP'\n",
    "    * latest like 'Y'\n",
    "  * Paste the link in the code cell below and **assign it to a descriptive Python name**\n",
    "  * **Load the data into Python** using the `geopandas` library, e.g.:\n",
    "\n",
    "  ```python\n",
    "  gpd.read_file(url)\n",
    "  ```\n",
    "  \n",
    "  * Call your `GeoDataFrame` name at the end of the cell for testing\n",
    "  \n",
    "  > `geopandas.GeoDataFrame` is an extension of `pandas.DataFrame` that contains spatial and geometric information and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "29861ba80f49a8b871ccf4eafe044859",
     "grade": false,
     "grade_id": "ans-boundary",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "23f3d8dae0897d17469f10ec34b4eb6d",
     "grade": true,
     "grade_id": "tests-boundary",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ans_gdf = _\n",
    "gdf_pts = 0\n",
    "\n",
    "if isinstance(ans_gdf, gpd.GeoDataFrame):\n",
    "    print('\\u2705 Great work! You downloaded and opened a GeoDataFrame')\n",
    "    gdf_pts +=2\n",
    "else:\n",
    "    print('\\u274C Hmm, your answer is not a GeoDataFrame')\n",
    "\n",
    "if len(ans_gdf)==1:\n",
    "    print('\\u2705 Great work! You selected a single fire')\n",
    "    gdf_pts +=2\n",
    "else:\n",
    "    print('\\u274C Hmm, your GeoDataFrame does not have the right length')\n",
    "\n",
    "if ans_gdf.incidentname.iloc[0]=='CAMP' and ans_gdf.latest.iloc[0]=='Y':\n",
    "    print('\\u2705 Great work! You selected the Camp fire perimeter')\n",
    "    gdf_pts +=2\n",
    "else:\n",
    "    print('\\u274C Hmm, that is not the latest Camp fire boundary')\n",
    "    \n",
    "print('\\u27A1 You earned {} of 5 points for downloading a fire boundary'\n",
    "      .format(gdf_pts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ad52b957923834c7ce35a240225f9574",
     "grade": false,
     "grade_id": "task-map",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Site Map\n",
    "\n",
    "The code below will help you to draw the Tribal subdivision boundaris on an interactive map.\n",
    "\n",
    "&#128187; Your task:\n",
    "  * Ask ChatGPT [how to plot a shapefile on a folium map](https://chat.openai.com/share/25988d5d-b355-4537-b2a1-71eafc60f67e)\n",
    "  * Adapt the code to use the boundary data you downloaded\n",
    "  * Add a labeled marker for Paradise, CA\n",
    "  * Center the map at that same location with a reasonable `zoom_start` level\n",
    "\n",
    "> **GOTCHA ALERT:** Make sure to call your map at the end of the cell so that it will display in your Notebook\n",
    "\n",
    "&#127798; Customize your plot - can you add ESRI World Imagery as the basemap/background?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "feae0ca9af096d0a8b031515fefd5993",
     "grade": false,
     "grade_id": "ans-map",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "564aea800165de24ed49e89c811937e9",
     "grade": false,
     "grade_id": "step-3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## STEP 3: DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "60a44e71e9c444dfe9963c9fa31fccc7",
     "grade": false,
     "grade_id": "instr-ndvi",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Observing vegetation health from space\n",
    "We will look at the destruction and recovery of vegetation in the area using the summertime (peak green) Normalized Difference Vegetation Index (NDVI). How does it work? First, we need to learn about spectral reflectance signatures.\n",
    "\n",
    "Every object reflects some wavelengths of light more or less than others. We can see this with our eyes, since, for example, plants reflect a lot of green in the summer, and then as that green diminishes in the fall they look more yellow or orange. The image below shows spectral signatures for water, soil, and vegetation:\n",
    "\n",
    "![](https://seos-project.eu/remotesensing/images/Reflexionskurven.jpg)\n",
    "> Image source: [SEOS Project](https://seos-project.eu/remotesensing/remotesensing-c01-p06.html)\n",
    "\n",
    "Healthy vegetation reflects a lot of Near-InfraRed (NIR) radiation. Less healthy vegetation reflects a similar amounts of the visible light spectra, but less NIR radiation. We don't see a huge drop in Green radiation until the plant is very stressed or dead. That means that NIR allows us to get ahead of what we can see with our eyes.\n",
    "\n",
    "![](https://camo.githubusercontent.com/176b39433ef30866421bf28988812852b94a7705c75764deebde846560aebbc6/68747470733a2f2f666c75726f7361742e636f6d2f77702d636f6e74656e742f75706c6f6164732f323031382f31302f67726f7774682d6d6f6e69746f72696e672d65313538333930323232383836372e706e6729)\n",
    "> Image source: [Spectral signature literature review by px39n](https://github.com/px39n/Awesome-Vegetation-Index)\n",
    "\n",
    "Different species of plants reflect different spectral signatures, but the *pattern* of the signatures are similar. NDVI compares the amount of NIR reflectance to the amount of Red reflectance, thus accounting for many of the species differences and isolating the health of the plant. The formula for calculating NDVI is:\n",
    "\n",
    "$$NDVI = \\frac{(NIR - Red)}{(NIR + Red)}$$\n",
    "\n",
    "&#128214; Read more about NDVI and other vegetation indices:\n",
    "  * [earthdatascience.org](https://www.earthdatascience.org/courses/use-data-open-source-python/multispectral-remote-sensing/vegetation-indices-in-python/calculate-NDVI-python/)\n",
    "  * [USGS](https://www.usgs.gov/landsat-missions/landsat-surface-reflectance-derived-spectral-indices)\n",
    "\n",
    "You will download NDVI data collected from the MODIS platform for the study period. MODIS is a multispectral instrument that measures Red and NIR data (and so can be used for NDVI). There are two MODIS sensors on two different platforms: satellites Terra and Aqua.\n",
    "\n",
    "&#128214; [Learn more about MODIS datasets and science](https://modis.gsfc.nasa.gov/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "443b830b01a886c5270d665a70a91592",
     "grade": false,
     "grade_id": "task-cite",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "&#9998; In the cell below, write a description of the data you will use. Make sure to include:\n",
    "  * A citation\n",
    "  * A brief explanation of the platform (Aqua satellite), sensor (MODIS), and post-processing (NDVI), including why these data will help you see vegetation recovery after a wildfire\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WRITE YOUR DATA DESCRIPTION AND CITATION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "90d490751417061e56d707ae000519d7",
     "grade": false,
     "grade_id": "instr-appdownload",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exploring the AppEEARS API for NASA Earthdata access\n",
    "\n",
    "We're going to ask for a special download that only covers our study area, so we can't just find a link to the data - we have to negotiate with the data server. We're doing this using the [APPEEARS](https://appeears.earthdatacloud.nasa.gov/) API (Application Programming Interface). The API makes it possible for you to request data using code. Luckily, the `earthpy` library you imported can complete the entire negotiation, including picking up where you left of downloading should you have to restart your kernel.\n",
    "\n",
    "> HINT: In order to download APPEEARS data, you will need and Earthdata account. `earthpy` will prompt you to store your username and password in your system keyring.\n",
    "\n",
    "&#128187; YOUR TASK: \n",
    "1. In the cell below, paste the following code as a starting point:\n",
    "\n",
    "    ```python\n",
    "    # Initialize AppeearsDownloader for MODIS NDVI data\n",
    "    ndvi_downloader = etapp.AppeearsDownloader(\n",
    "        download_key='modis-ndvi',\n",
    "        ea_dir=project_dir,\n",
    "        product='',\n",
    "        layer='',\n",
    "        start_date='',\n",
    "        end_date='',\n",
    "        recurring=,\n",
    "        year_range=,\n",
    "        polygon=gdf\n",
    "    )\n",
    "    \n",
    "    # Download files if the download directory does not exist\n",
    "    if not os.path.exists(ndvi_downloader.data_dir):\n",
    "        ndvi_downloader.download_files()\n",
    "    \n",
    "    ndvi_downloader\n",
    "    ```\n",
    "2. Modify `project_dir` to match **your** project directory name, and `gdf` to match the name of **your** `GeoDataFrame`.\n",
    "3. Fill out the parameters so that you are downloading the highest **available** resolution **NDVI** layer of the **Aqua MODIS** platform from **Summer months (June, July, August) of 2017 to 2022**.\n",
    "\n",
    "  > **HINT**: You will need to consult with the [list of APPEEARS datasets](https://appeears.earthdatacloud.nasa.gov/products).\n",
    "\n",
    "  > **GOTCHA ALERT**: The product name will need to be formatted as `<product-name>.<version>`\n",
    "\n",
    "4. Run the code. Note that orders from the APPEEARS API can take a few hours to be delivered. Check your status by logging in at [the Appeears status page](https://appeears.earthdatacloud.nasa.gov/explore)\n",
    "   \n",
    "   > **GOTCHA ALERT**: If your download fails, but your download directory has been created, this code will not initialize a new download. To start over fresh, delete the download directory in the Terminal OR change the `download_key`.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e316f977498770de1930aa52deb79db7",
     "grade": false,
     "grade_id": "ans-appdownload",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bec50593d9e07386ed12d0401b342de7",
     "grade": true,
     "grade_id": "tests-appdownload",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# RUN THIS CELL TO TEST YOUR WORK - DO NOT MODIFY!\n",
    "ans_download = _\n",
    "download_pts = 0\n",
    "\n",
    "if os.path.exists(ndvi_downloader.data_dir):\n",
    "    print('\\u2705 Great work! You started your download')\n",
    "    download_pts += 1\n",
    "else:\n",
    "    print('\\u274C Hmm, looks like your data did not download')\n",
    "\n",
    "if len(glob(os.path.join(ndvi_downloader.data_dir, '*', '*')))==82:\n",
    "    print('\\u2705 Great work! Your download succeeded')\n",
    "    download_pts += 4\n",
    "else:\n",
    "    print('\\u274C Hmm, looks like your data did not download')\n",
    "\n",
    "# Subtract one point for any PEP-8 errors\n",
    "tmp_path = \"tmp.py\"\n",
    "with open(tmp_path, \"w\") as tmp_file:\n",
    "    tmp_file.write(In[-2])\n",
    "ignore_flake8 = 'W292,F401,E302,F821'\n",
    "flake8_out = subprocess.run(\n",
    "    ['flake8', \n",
    "     '--ignore', ignore_flake8, \n",
    "     '--import-order-style', 'edited',\n",
    "     '--count', \n",
    "     tmp_path],\n",
    "    stdout=subprocess.PIPE,\n",
    ").stdout.decode(\"ascii\")\n",
    "print(flake8_out)\n",
    "download_pts -= int(flake8_out.splitlines()[-1])\n",
    "\n",
    "print('\\u27A1 You earned {} of 5 points for downloading data'\n",
    "      .format(download_pts))\n",
    "\n",
    "download_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b9fc19a0b63a64bc0f78048c0039ebd1",
     "grade": false,
     "grade_id": "instr-glob",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Putting it together: Working with multi-file raster datasets in Python\n",
    "\n",
    "Now you need to load all the downloaded files into Python. Let's start by getting all the file names. You will also need to extract the date from the filename. Check out [the lesson on getting information from filenames in the textbook](https://www.earthdatascience.org/courses/intro-to-earth-data-science/write-efficient-python-code/loops/data-workflows-with-loops/).\n",
    "\n",
    "> **GOTCHA ALERT:** `glob` doesn't necessarily find files in the order you would expect. Make sure to **sort** your file names like it says in the textbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e1bc37e1716354b4b386886e61fa2fa9",
     "grade": false,
     "grade_id": "ans-glob",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "83d238ebec333a7c4584605b11fe107a",
     "grade": true,
     "grade_id": "tests-glob",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# RUN THIS CELL TO TEST YOUR CODE - DO NOT MODIFY!\n",
    "ans_glob = _\n",
    "glob_pts = 0\n",
    "\n",
    "if len(ans_glob)==41:\n",
    "    print('\\u2705 Great work! Your correctly filtered your files')\n",
    "    glob_pts += 5\n",
    "else:\n",
    "    print('\\u274C Hmm, looks like you did not find the correct files')\n",
    "\n",
    "# Subtract one point for any PEP-8 errors\n",
    "tmp_path = \"tmp.py\"\n",
    "with open(tmp_path, \"w\") as tmp_file:\n",
    "    tmp_file.write(In[-2])\n",
    "ignore_flake8 = 'W292,F401,E302,F821'\n",
    "flake8_out = subprocess.run(\n",
    "    ['flake8', \n",
    "     '--ignore', ignore_flake8, \n",
    "     '--import-order-style', 'edited',\n",
    "     '--count', \n",
    "     tmp_path],\n",
    "    stdout=subprocess.PIPE,\n",
    ").stdout.decode(\"ascii\")\n",
    "print(flake8_out)\n",
    "glob_pts -= int(flake8_out.splitlines()[-1])\n",
    "\n",
    "print('\\u27A1 You earned {} of 5 points for getting file names'\n",
    "      .format(glob_pts))\n",
    "\n",
    "glob_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4 - IMPORT DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e37bef6624f7a538cbc2ca155d66af00",
     "grade": false,
     "grade_id": "instr-load",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Repeating tasks in Python\n",
    "\n",
    "Now you should have dozens of files! For each file, you need to:\n",
    "  * Load the file in using the `rioxarray` library\n",
    "  * Get the date from the file name\n",
    "  * Add the date as a dimension coordinate\n",
    "  * Give your data variable a name\n",
    "  * Divide by the scale factor of 10000\n",
    "\n",
    "You don't want to write out the code for each file -- That's a recipe for copy pasta. Luckily, Python has tools for doing similar tasks repeatedly. In this case, you'll use one called a `for` loop.\n",
    "\n",
    "Check out the [textbook page on `for` loops](https://www.earthdatascience.org/courses/intro-to-earth-data-science/write-efficient-python-code/loops/automate-data-tasks-with-loops/)\n",
    "\n",
    "There's some code below that uses a `for` loop in what is called an **accumulation pattern** to process each file. That means that you will save the results of your processing to a list each time you process the files, and then merge all the arrays in the list. \n",
    "\n",
    "```python\n",
    "ndvi_das = []\n",
    "for ndvi_path in ndvi_paths:\n",
    "    # Get date from file name\n",
    "    doy = ndvi_path[doy_start:doy_end]\n",
    "    date = pd.to_datetime(doy, format='')\n",
    "\n",
    "    # Open dataset\n",
    "    da = rxr.open_rasterio(ndvi_path, masked=True).squeeze()\n",
    "\n",
    "    # Prepare to concatenate: Add date dimension and clean up metadata\n",
    "    da = da.assign_coords({'date': date})\n",
    "    da = da.expand_dims({'date': 1})\n",
    "    da.name = 'NDVI'\n",
    "\n",
    "    # Divide by scale factor\n",
    "\n",
    "    # Add the DataArray to the end of the accumulator list\n",
    "\n",
    "ndvi_das\n",
    "```\n",
    "\n",
    "Your task is to:\n",
    "  1. Replace any names with your chosen variable names\n",
    "  2. Look at the file names. How many characters from the end is the beginning of the date? The end of the date? Define the missing names `doy_start`, `doy_end`.\n",
    "  3. Assign the name `scale_factor` the correct value for this NDVI dataset (HINT: NDVI should range between 0 and 1)\n",
    "  4. Put the correct **format string** for this application in the `pd.to_datetime` function\n",
    "  5. Add the code needed to divide by the scale factor and stick the now-loaded DataArray at the end of your list of DataArrays (accumulate).\n",
    "  \n",
    "&#127798; You can also get the date with a tool called a regular expression (`re` library). See if you can get the code working that way too! You may find it helpful to test your regular expression at this [regex tester site](https://regex101.com/).\n",
    "\n",
    "> HINT: **DO NOT** try to complete all these steps without running your code! Use these debugging tips:\n",
    ">   * Comment out code you haven't gotten to yet\n",
    ">   * Complete one step at a time\n",
    ">   * Test your work by looking at the results before moving on to the next step\n",
    ">   * Use the `break` keyword at the end of your `for` loop (or a breakpoint) to run the code on only the first `DataArray`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ce8dee4bbb7b1639f031f6642e396d1",
     "grade": false,
     "grade_id": "ans-load",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "62c0a761f09e30e9985b0e4908382d6e",
     "grade": true,
     "grade_id": "tests-load",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# RUN THIS CELL TO TEST YOUR WORK - DO NOT MODIFY!\n",
    "ans_open = _\n",
    "open_pts = 0\n",
    "\n",
    "# Check that the called value is a list of DataArrays\n",
    "if all([isinstance(da, xr.DataArray) for da in ans_open]):\n",
    "    print('\\u2705 Great work! You loaded your data into DataArrays')\n",
    "    open_pts += 2\n",
    "else:\n",
    "    print('\\u274C Hmm, looks like you have not loaded your data yet')\n",
    "\n",
    "# Check that there are the right number of DataArrays\n",
    "if len(ans_open)==41:\n",
    "    print('\\u2705 Great work! Your loaded all the DataArrays')\n",
    "    open_pts += 2\n",
    "else:\n",
    "    print('\\u274C Hmm, looks like you have too few or too many DataArrays')\n",
    "\n",
    "# Check that there is a datetime coordinate\n",
    "has_dt_coord_list = []\n",
    "for da in ans_open:\n",
    "    has_dt_coord = False\n",
    "    for name, coord in da.coords.items():\n",
    "        try:\n",
    "            coord.dt\n",
    "            has_dt_coord = True\n",
    "        except TypeError:\n",
    "            pass\n",
    "    has_dt_coord_list.append(has_dt_coord)\n",
    "if all(has_dt_coord_list):\n",
    "    print('\\u2705 Great work! You added a Datetime Coordinate')\n",
    "    open_pts += 4\n",
    "else:\n",
    "    print('\\u274C Hmm, looks like you did not add a date coordinate '\n",
    "          'or you did not correctly convert your dates')\n",
    "\n",
    "# Check that the scale factor was applied\n",
    "if (all([(da.max() <= 1) for da in ans_open]) \n",
    "        and all([(da.min() >= -1) for da in ans_open])):\n",
    "    print('\\u2705 Great work! You correctly scaled your data')\n",
    "    open_pts += 2\n",
    "else:\n",
    "    print('\\u274C Hmm, looks like you did not scale your data')\n",
    "\n",
    "# Subtract one point for any PEP-8 errors\n",
    "tmp_path = \"tmp.py\"\n",
    "with open(tmp_path, \"w\") as tmp_file:\n",
    "    tmp_file.write(In[-2])\n",
    "ignore_flake8 = 'W292,F401,E302,F821'\n",
    "flake8_out = subprocess.run(\n",
    "    ['flake8', \n",
    "     '--ignore', ignore_flake8, \n",
    "     '--import-order-style', 'edited',\n",
    "     '--count', \n",
    "     tmp_path],\n",
    "    stdout=subprocess.PIPE,\n",
    ").stdout.decode(\"ascii\")\n",
    "print(flake8_out)\n",
    "open_pts -= int(flake8_out.splitlines()[-1])\n",
    "\n",
    "print('\\u27A1 You earned {} of 10 points for downloading data'\n",
    "      .format(open_pts))\n",
    "\n",
    "open_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4263cf7ddc7398e91dd3990d8680a4fd",
     "grade": false,
     "grade_id": "instr-combine",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Next, stack your arrays by date into a time series using the `xr.combine_by_coords()` function. You will have to tell it which **dimension** you want to stack your data in, using the `coords=['dimension_name']` parameter.\n",
    "\n",
    "> HINT: which dimension do you want to get longer?\n",
    "\n",
    "> GOTCHA ALERT: The `coords` parameter must be a list, even if there is only one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d7d5f163492e6826cc683156300e6d8b",
     "grade": false,
     "grade_id": "ans-combine",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b045a446306fa6a12b88f7b36dcfa011",
     "grade": true,
     "grade_id": "tests-combine",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# RUN THIS CELL TO TEST YOUR WORK - DO NOT MODIFY!\n",
    "ans_combine = _\n",
    "combine_pts = 0\n",
    "\n",
    "# Check that the called value is a Dataset\n",
    "if isinstance(ans_combine, xr.Dataset):\n",
    "    print('\\u2705 Great work! You combined your data into a Dataset')\n",
    "    combine_pts += 1\n",
    "else:\n",
    "    print('\\u274C Hmm, did you call your combined Dataset?')\n",
    "\n",
    "# Check that there are the right number of DataArrays\n",
    "if ans_combine.dims=={'x': 205, 'y': 144, 'date': 41}:\n",
    "    print('\\u2705 Great work! Your loaded all the DataArrays')\n",
    "    combine_pts += 2\n",
    "else:\n",
    "    print('\\u274C Hmm, looks like you have too few or too many '\n",
    "          'DataArrays')\n",
    "\n",
    "# Subtract one point for any PEP-8 errors\n",
    "tmp_path = \"tmp.py\"\n",
    "with open(tmp_path, \"w\") as tmp_file:\n",
    "    tmp_file.write(In[-2])\n",
    "ignore_flake8 = 'W292,F401,E302,F821'\n",
    "flake8_out = subprocess.run(\n",
    "    ['flake8', \n",
    "     '--ignore', ignore_flake8, \n",
    "     '--import-order-style', 'edited',\n",
    "     '--count', \n",
    "     tmp_path],\n",
    "    stdout=subprocess.PIPE,\n",
    ").stdout.decode(\"ascii\")\n",
    "print(flake8_out)\n",
    "combine_pts -= int(flake8_out.splitlines()[-1])\n",
    "\n",
    "print('\\u27A1 You earned {} of 3 points for downloading data'\n",
    "      .format(combine_pts))\n",
    "\n",
    "combine_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b332a29ef59bbb5893eda758d7c5e8f7",
     "grade": false,
     "grade_id": "task-plot-map",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Plot the change in NDVI spatially\n",
    "\n",
    "&#128187; **YOUR TASK:** Complete the following (ask ChatGPT or look in the xarray documentation if you aren't sure how to complete the first 4 steps):\n",
    "  1. Select data from 2019 using the `.sel()` method\n",
    "  2. Take the temporal mean (over the **date**, not spatially) using the `.mean()` method\n",
    "  3. Repeat for the data from 2017\n",
    "  4. Subtract the pre-fire year from the post-fire years\n",
    "  5. Plot the result\n",
    "\n",
    "> **HINT**: You can use the `hvplot()` method with an `xarray.Dataset` too! When plotting maps, there are many considerations related to the type of geographic coordinates you are using. `hvplot` can take care of a lot of that for you, provided that the `geoviews` package is installed (which it should be for you). However, to use the plotting methods that avoid a warped image you **must** include the parameter `geo=True`, as well as specifying `x='x'` and `y='y'`.\n",
    "    \n",
    "  6. Use a **diverging** color map, e.g. by chaining `.opts(cmap='PiYG')` onto the end of your spatial plotting code.\n",
    "\n",
    "> There are different types of color maps for different types of data. In this case, we want decreases to be a different color from increases, so we use a **diverging** color map. Check out available colormaps in the [matplotlib documentation](https://matplotlib.org/stable/tutorials/colors/colormaps.html).\n",
    "\n",
    "&#127798; For an extra challenge, add the Camp Fire Boundary to the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c88e92d6e3ac19209c8600e85a03b606",
     "grade": false,
     "grade_id": "ans-plot-map",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bd70cefd09be91d633d6524b00b1eb41",
     "grade": false,
     "grade_id": "instr-out",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Did the NDVI drop more inside the fire boundary than nearby?\n",
    "\n",
    "You will compute the mean NDVI inside and outside the fire boundary. I have tried asking ChatGPT how to accomplish this [in this chat](https://chat.openai.com/share/ea0a406d-7344-4bd4-ba66-f25e82e6a9fb). I got a useful response, but I wasn't able to get a workflow from ChatGPT that did not require the **envelope** of the fire boundary as a separate file.\n",
    "\n",
    "> NOTE: An **envelope** of a shape is the smallest rectangle that contains the entire shape.\n",
    "\n",
    "&#128187; **YOUR TASK:**\n",
    "  1. First, use the code below to get the envelope of the fire boundary as a `GeoDataFrame`:\n",
    "\n",
    "    ```python\n",
    "    gpd.GeoDataFrame(geometry=gdf.envelope)\n",
    "    ```\n",
    "    \n",
    "  2. Use the code from ChatGPT as a starting point, or writing your own, get the geometric difference between the envelope and the fire boundary as a `GeoDataFrame`\n",
    "\n",
    "  3. Test if the geometry was modified correctly -- Add some code to help you take a look at the results.\n",
    "\n",
    "> HINT: You can use the `hvplot()` method to plot `GeoDataFrame`s too, so you can check that the code works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9b2a49637bcc563394fc7aef8d5bcb2b",
     "grade": false,
     "grade_id": "ans-out",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "63cd54acdb2839305e1e8d2f475feed7",
     "grade": true,
     "grade_id": "tests-out",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# RUN THIS CELL TO TEST YOUR CODE - DO NOT MODIFY!\n",
    "ans_out = _\n",
    "out_pts = 0\n",
    "\n",
    "if int(round(out_gdf.to_crs(26910).area, -4))==589960000:\n",
    "    print('\\u2705 Great work! Your correctly took a spatial difference')\n",
    "    out_pts += 5\n",
    "else:\n",
    "    print('\\u274C Hmm, looks like your spatial difference is incorrect')\n",
    "\n",
    "# Subtract one point for any PEP-8 errors\n",
    "tmp_path = \"tmp.py\"\n",
    "with open(tmp_path, \"w\") as tmp_file:\n",
    "    tmp_file.write(In[-2])\n",
    "ignore_flake8 = 'W292,F401,E302,F821'\n",
    "flake8_out = subprocess.run(\n",
    "    ['flake8',\n",
    "     '--ignore', ignore_flake8,\n",
    "     '--import-order-style', 'edited',\n",
    "     '--count',\n",
    "     tmp_path],\n",
    "    stdout=subprocess.PIPE,\n",
    ").stdout.decode(\"ascii\")\n",
    "print(flake8_out)\n",
    "out_pts -= int(flake8_out.splitlines()[-1])\n",
    "\n",
    "print('\\u27A1 You earned {} of 5 points for getting file names'\n",
    "      .format(out_pts))\n",
    "\n",
    "out_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2ee442ad9e0cb2a6fd0bff71957d18d0",
     "grade": false,
     "grade_id": "instr-clip",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "&#128187; **YOUR TASK:** Clip your DataArray to the boundaries for both inside and outside the reservation. You will need to replace the `GeoDataFrame` name with your own. Check out the [lesson on clipping data with the `rioxarray` library in the textbook](https://www.earthdatascience.org/courses/use-data-open-source-python/intro-raster-data-python/raster-data-processing/crop-raster-data-with-shapefile-in-python/).\n",
    "\n",
    "> **GOTCHA ALERT:** It's important to use `from_disk=True` when clipping large arrays like this. It allows the computer to use less valuable memory resources when clipping - you will probably find that otherwise the cell below crashes the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "858af57583a902c647353720fbff3fb2",
     "grade": false,
     "grade_id": "ans-clip",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5e91fbe0cd454111c70ab49f5a14d655",
     "grade": false,
     "grade_id": "task-diff",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "&#128187; **YOUR TASK:** Practice chaining `xarray` methods! For **both inside and outside** the Camp fire boundary:\n",
    "  1. Group the data by year using\n",
    "  2. Take the mean. You always need to tell reducing methods in `xarray` what dimensions you want to reduce. When you want to summarize data across **all** dimensions (except the group dimension(s)), you can use the `...` syntax, e.g. `.mean(...)` as a shorthand.\n",
    "  3. Select the NDVI variable\n",
    "  4. Convert to a `DataFrame` using the `to_dataframe()` method\n",
    "  5. Call **both** of your `DataFrame`s at the end of the cell for testing, e.g.\n",
    "     ```python\n",
    "     inside_df, outside_df\n",
    "     ```\n",
    "\n",
    "> **GOTCHA ALERT:** the DateIndex in pandas is a little different from the Datetime Dimension in xarray. You will need to use the `.dt.year` syntax to access information about the year, not just `.year`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc2e3e3da18ba398dc1ad2b6ec04c637",
     "grade": false,
     "grade_id": "ans-diff",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "026c6716dbb109e20c1929cb68b4d21a",
     "grade": true,
     "grade_id": "tests-diff",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# RUN THIS CELL TO TEST YOUR CODE - DO NOT MODIFY!\n",
    "print(_)\n",
    "(ans_in, ans_out) = _\n",
    "out_pts = 0\n",
    "\n",
    "if round((ans_in - ans_out).sum(), 2).sum()==-0.29:\n",
    "    print('\\u2705 Great work! Your correctly clipped your data')\n",
    "    out_pts += 5\n",
    "else:\n",
    "    print('\\u274C Hmm, looks like your clipping is incorrect')\n",
    "\n",
    "# Subtract one point for any PEP-8 errors\n",
    "tmp_path = \"tmp.py\"\n",
    "with open(tmp_path, \"w\") as tmp_file:\n",
    "    tmp_file.write(In[-2])\n",
    "ignore_flake8 = 'W292,F401,E302,F821'\n",
    "flake8_out = subprocess.run(\n",
    "    ['flake8',\n",
    "     '--ignore', ignore_flake8,\n",
    "     '--import-order-style', 'edited',\n",
    "     '--count',\n",
    "     tmp_path],\n",
    "    stdout=subprocess.PIPE,\n",
    ").stdout.decode(\"ascii\")\n",
    "print(flake8_out)\n",
    "out_pts -= int(flake8_out.splitlines()[-1])\n",
    "\n",
    "print('\\u27A1 You earned {} of 5 points for clipping'\n",
    "      .format(out_pts))\n",
    "\n",
    "out_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9815a35a147261ba91724fe251abeed0",
     "grade": false,
     "grade_id": "task-diff-plot",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "&#128187; YOUR TASK:\n",
    "  1. Take the difference between outside and inside the Reservation\n",
    "     > GOTCHA ALERT: You may need to select the NDVI columns of your inside/outside `DataFrame`s in order to subtract effectively\n",
    "  2. Save it as a new column in your `DataFrame`\n",
    "  3. Plot the difference. What do you observe? Don't forget to write a **headline and description** of your plot!\n",
    "\n",
    "&#127798; For an extra challenge, add a vertical line showing when the fire occurred. Note that unfortunately you will need to convert the date to a decimal of a year. You may find the pandas datetime method `.toordinal()` useful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ff499daec2699133a2be0e944db3077",
     "grade": false,
     "grade_id": "ans-diff-plot",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5519198e00659e5f4c7a56e81955ff1b",
     "grade": true,
     "grade_id": "headline",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ec5e521a234f921e91f2e972192720d1",
     "grade": false,
     "grade_id": "instr-repeat-workflow",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Your turn! Repeat this workflow in a different time and place for your portfolio.\n",
    "\n",
    "It's not just water rights that affect NDVI! You could look at: \n",
    "  * Recovery after a national disaster, like a wildfire or hurricane\n",
    "  * The effects of drought on crop health\n",
    "  * Deforestation\n",
    "\n",
    "You can even choose a different dataset, like Landsat, and/or a different spectral index. [Check out some other ways to enhance images and highlight different phenomena](https://www.usgs.gov/landsat-missions/landsat-surface-reflectance-derived-spectral-indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
